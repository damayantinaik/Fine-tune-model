{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/damayantinaik/Fine-tune-model/blob/main/Fine_tuning_Multilingual_NER_LLM_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79gey1U00BVI"
      },
      "source": [
        "# **Fine-Tuning Multilingual Named Entity Recognition LLM model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fm_pd9G4z_0"
      },
      "source": [
        "Named Entity Recognition (NER) is very popular common task that identifies entities like person, organization, location in text. These entities can be used for many applications such as gaining insights from company documents, augmenting the quality of search engines, or building a structured database from a corpus.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6fnbIOP8tco"
      },
      "source": [
        "In this project, I'll show how a single transformer model called \"XLM-RoBERTa\" can be fine-tuned to perform named entity recognition across several labnguages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZNy69XpOPZP"
      },
      "source": [
        "To carry out the task, I'm choosing to perform NER for Switzerland based customers, where there are four national languages German, French, Italian, and English (with English often serving as bridge between them).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsSc58CclWHV"
      },
      "source": [
        "# **Multilingual Transformers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZxRGDd_hwc5"
      },
      "source": [
        "Multilingual transformers involve similar architecture and training procedures as monolingual counterparts. The only difference is that the multilingual transformers are trained on corpus created from multilanguage documents as compared to monolingual transformers where the later is only trained on corpus of one language. Multilingual transformers are able to generalize well across languages for a variety of down stream tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfXVx4UglwuX"
      },
      "source": [
        "One efficient multilingual Transformers is the XLM-RoBERTa (also called XLM-R). It has a large dataset, uses \"SentencePiece\" to tokenize the raw text. In this project, I'll fine-tune the model to obatin the maximum performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbQs28hwNHS5"
      },
      "source": [
        "# **The Dataset**\n",
        "The dataset that I am going to use is a subset of XTREME (Cross-lingual TRansfer Evaluation of Multilingual Encoders) dataset from Hugging Face hub called WikiANN or PAN-X. This dataset consists of Wikipedia articles in many languages (176 languages), with labels for tagging tokens as person, location or organization using IOB-2 (Inside-Outside-Begining-2) format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oiLjuh0OqBy"
      },
      "source": [
        "# **Load the dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALCqHulCZKSt"
      },
      "source": [
        "A datset comes in confugrations like 'cola', 'PAN-X', 'sst2', 'mrpc', 'qqp', 'stsb', 'mnli' etc, so, before we load our dataset in PAN-X configuration,  let us have a look on the configurations that it comes with and load the one we are interested in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAXXDRegZO9i"
      },
      "outputs": [],
      "source": [
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdNHupeBZPLz",
        "outputId": "220fbf91-9d90-4a16-df0b-e8dc4ca2f7df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XTREME has 183 configurations\n"
          ]
        }
      ],
      "source": [
        "from datasets import get_dataset_config_names\n",
        "xtreme_subsets = get_dataset_config_names('xtreme')\n",
        "print(f\"XTREME has {len(xtreme_subsets)} configurations\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7hmUQ-zY_m_"
      },
      "source": [
        "# **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GRG5L1zaeqP",
        "outputId": "17054025-5c0a-4868-83e8-4c8ba9465e23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['MLQA.ar.ar', 'MLQA.ar.de', 'MLQA.ar.en', 'MLQA.ar.es', 'MLQA.ar.hi']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xtreme_subsets[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7AAtGNgbPbs"
      },
      "source": [
        "The PAN-X (WikiANN) datset is specifically designed for training and evaluating NER that can identify and classify person, location and organization within text across multiple languages. The dataset is based on Wikipedia articles and annotated with location (LOC), person(PER) and organization(ORG) tags in IOB2 (Inside, Outside, Begining,  2)format.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BArViQaduwj"
      },
      "source": [
        "So, we'll only look for the configuration that starts with \"PAN\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SzUGps-bNCk"
      },
      "outputs": [],
      "source": [
        "panx_subset = [s for s in xtreme_subsets if s.startswith(\"PAN\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DrIJbN3bNQz",
        "outputId": "3d7721a0-87c8-4a7c-e8ac-c0d882d00868"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['PAN-X.af',\n",
              " 'PAN-X.ar',\n",
              " 'PAN-X.bg',\n",
              " 'PAN-X.bn',\n",
              " 'PAN-X.de',\n",
              " 'PAN-X.el',\n",
              " 'PAN-X.en',\n",
              " 'PAN-X.es',\n",
              " 'PAN-X.et',\n",
              " 'PAN-X.eu']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "panx_subset[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw1dtx7Kem-1"
      },
      "source": [
        "As there are four languages in Swizerland, to make a Swiss corpus, we'll sample the German(de), French(fr), Italian(it) and English(en) from PAN-X configuration(of course according to their spoken proportion): <br>\n",
        "German(62.9%) <br> French(22.9%) <br> Italian (8.4%) <br> English(5.9%)<br>\n",
        "\n",
        "Although imbalanced, this datset will represent the real-world dataset, where the numebr of samples from all languages are not always of same number. This happens because of the lack of expertise in minority languages. The de, fr, it, and en represents German, French, Itialian and English languages respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jG-kd5ZYNVgi"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from datasets import DatasetDict, load_dataset\n",
        "\n",
        "langs = ['de', 'fr', 'it', 'en']\n",
        "fracs = [0.629, 0.229, 0.084, 0.059]\n",
        "\n",
        "panx_ch = defaultdict(DatasetDict)\n",
        "\n",
        "for lang, frac in zip(langs, fracs):\n",
        "  # Load monolingual corpus\n",
        "  ds = load_dataset(f\"xtreme\", name = f\"PAN-X.{lang}\") # name: dataset configuration (or also called subset)\n",
        "# print(ds)\n",
        "# ds['train'][0]\n",
        "  for split in ds: # Split here is train, validation and test\n",
        "    panx_ch[lang][split] = ds[split].select(range(int(frac * len(ds[split]))))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "j7wL_OxXe21Z",
        "outputId": "482ff38b-13e2-448b-8114-444950445c6c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"de\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 12580,\n        \"max\": 12580,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          12580\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 4580,\n        \"max\": 4580,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4580\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1680,\n        \"max\": 1680,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1680\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"en\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1180,\n        \"max\": 1180,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1180\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7a3bb151-ffd0-4269-b94d-bf936c02bf5e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>de</th>\n",
              "      <th>fr</th>\n",
              "      <th>it</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Number of training examples</th>\n",
              "      <td>12580</td>\n",
              "      <td>4580</td>\n",
              "      <td>1680</td>\n",
              "      <td>1180</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a3bb151-ffd0-4269-b94d-bf936c02bf5e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a3bb151-ffd0-4269-b94d-bf936c02bf5e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a3bb151-ffd0-4269-b94d-bf936c02bf5e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                de    fr    it    en\n",
              "Number of training examples  12580  4580  1680  1180"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs}, index = ['Number of training examples'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uvl4l6smru8",
        "outputId": "68a7a60c-73c7-42c6-b1f5-3cf828fb25ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'tokens': [['als', 'Teil', 'der', 'Savoyer', 'Voralpen', 'im', 'Osten', '.'],\n",
              "  ['WEITERLEITUNG', 'Antonina', 'Wladimirowna', 'Kriwoschapka'],\n",
              "  ['**', \"''\", 'Lou', 'Salomé', \"''\", '.']],\n",
              " 'ner_tags': [[0, 0, 0, 5, 6, 0, 0, 0], [0, 1, 2, 2], [0, 0, 1, 2, 0, 0]],\n",
              " 'langs': [['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de'],\n",
              "  ['de', 'de', 'de', 'de'],\n",
              "  ['de', 'de', 'de', 'de', 'de', 'de']]}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "panx_ch['de'][\"train\"][:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FzpiTziGl8r",
        "outputId": "80c959e9-1b97-48f8-ddd7-1cdbeb8a8586"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'tokens': List(Value('string')),\n",
              " 'ner_tags': List(ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'])),\n",
              " 'langs': List(Value('string'))}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "panx_ch['de']['train'].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSctV3kynNW3",
        "outputId": "bf814801-1a28-44ab-f2c9-0ab34ea80f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'])\n",
            "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n"
          ]
        }
      ],
      "source": [
        "tags = panx_ch['de']['train'].features['ner_tags'].feature\n",
        "print(tags)\n",
        "print(tags.names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-iCFvs2rwIC",
        "outputId": "65225ac9-d60d-4c64-9c37-d65fc051b369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'tokens': ['als', 'Teil', 'der', 'Savoyer', 'Voralpen', 'im', 'Osten', '.'],\n",
              " 'ner_tags': [0, 0, 0, 5, 6, 0, 0, 0],\n",
              " 'langs': ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de'],\n",
              " 'ner_tags_str': ['O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O']}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert the number to human readable string tags by using int2str() method on ClassLabel object\n",
        "# The above can be obtained by a function as defined below\n",
        "def create_tag_names(batch):\n",
        "  return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n",
        "\n",
        "panx_de = panx_ch['de'].map(create_tag_names)\n",
        "\n",
        "# Let us check the 1st row\n",
        "de_example = panx_de['train'][0]\n",
        "de_example\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79IoHWd3OBah"
      },
      "source": [
        "Let us check the English train dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYepEF7ztC2y",
        "outputId": "5db70cff-15d6-4d40-cad0-3fc4e3a5993e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'tokens': [['R.H.',\n",
              "   'Saunders',\n",
              "   '(',\n",
              "   'St.',\n",
              "   'Lawrence',\n",
              "   'River',\n",
              "   ')',\n",
              "   '(',\n",
              "   '968',\n",
              "   'MW',\n",
              "   ')'],\n",
              "  [';', \"'\", \"''\", 'Anders', 'Lindström', \"''\", \"'\"],\n",
              "  ['Karl', 'Ove', 'Knausgård', '(', 'born', '1968', ')']],\n",
              " 'ner_tags': [[3, 4, 0, 3, 4, 4, 0, 0, 0, 0, 0],\n",
              "  [0, 0, 0, 1, 2, 0, 0],\n",
              "  [1, 2, 2, 0, 0, 0, 0]],\n",
              " 'langs': [['en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en'],\n",
              "  ['en', 'en', 'en', 'en', 'en', 'en', 'en'],\n",
              "  ['en', 'en', 'en', 'en', 'en', 'en', 'en']]}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "panx_ch['en'][\"train\"][:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZIjcUcOtV5o",
        "outputId": "9959e0f1-da63-47f9-dd08-df5fe7146e51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'tokens': List(Value('string')),\n",
              " 'ner_tags': List(ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'])),\n",
              " 'langs': List(Value('string'))}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "panx_ch['en']['train'].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rELqt0JZvrps"
      },
      "outputs": [],
      "source": [
        "tags2 = panx_ch['en']['train'].features['ner_tags'].feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_PbhaF-vzMp",
        "outputId": "1ac1b2e1-84d5-4976-bb6d-b075bdcde465"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tags2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76MLyqhGv91l"
      },
      "outputs": [],
      "source": [
        "tags_arrangement = panx_ch['en']['train']['ner_tags'][0:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC7dzv3FwJ6o",
        "outputId": "fed02709-6e29-4af4-eef6-4e95c0c98e3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[3, 4, 0, 3, 4, 4, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 2, 0, 0],\n",
              " [1, 2, 2, 0, 0, 0, 0]]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tags_arrangement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXTkQt9Ham6f"
      },
      "source": [
        "**Let us check the datset to see we don't have unusual imbalance in the tags. Let us check the frequencies of the tags.**  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "MaZSM_QFsVtd",
        "outputId": "1b0f6eef-4769-469c-efd7-0752bb7998c3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"LOC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1698,\n        \"min\": 3127,\n        \"max\": 6089,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6089,\n          3127,\n          3166\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PER\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1652,\n        \"min\": 2891,\n        \"max\": 5778,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5778,\n          2891,\n          2942\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ORG\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1634,\n        \"min\": 2509,\n        \"max\": 5434,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5434,\n          2707,\n          2509\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-57e0fbc7-9d78-4a3f-b4c4-b7bbb8d88b05\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LOC</th>\n",
              "      <th>PER</th>\n",
              "      <th>ORG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>6089</td>\n",
              "      <td>5778</td>\n",
              "      <td>5434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>validation</th>\n",
              "      <td>3127</td>\n",
              "      <td>2891</td>\n",
              "      <td>2707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>3166</td>\n",
              "      <td>2942</td>\n",
              "      <td>2509</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57e0fbc7-9d78-4a3f-b4c4-b7bbb8d88b05')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-57e0fbc7-9d78-4a3f-b4c4-b7bbb8d88b05 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-57e0fbc7-9d78-4a3f-b4c4-b7bbb8d88b05');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ece216d5-0d7b-4753-961c-991627f88ee9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ece216d5-0d7b-4753-961c-991627f88ee9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ece216d5-0d7b-4753-961c-991627f88ee9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "             LOC   PER   ORG\n",
              "train       6089  5778  5434\n",
              "validation  3127  2891  2707\n",
              "test        3166  2942  2509"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "split2freqs = defaultdict(Counter)\n",
        "for split, dataset in panx_de.items(): # Here split is the train, validation, test\n",
        "  for row in dataset[\"ner_tags_str\"]:\n",
        "    for tag in row:\n",
        "      if tag.startswith(\"B\"):\n",
        "        tag_type = tag.split(\"-\")[1]\n",
        "        split2freqs[split][tag_type] +=1\n",
        "pd.DataFrame.from_dict(split2freqs, orient = 'index')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWsS-RTloUVy"
      },
      "source": [
        "The distribution of LOC, PER and ORG are nearly same in each split, so it is good to proceed further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWjJCIjTmWpp"
      },
      "source": [
        "# **Tokenization using XLM-R**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z17a2NFcmrKA"
      },
      "source": [
        "## **Tokenizer pipeline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxq8mL6Gmwl_"
      },
      "source": [
        "The tokenization is not a single step but a pipeline with multiple steps. The steps are:<br>\n",
        "**1. Normalization**<br>\n",
        "This steps involves <br>a. Stripping white space <br>b. removing accented characters <br>c. Unicode normailization (i.e writing the same character in various ways) <br>d. lowercasing the text (if needed) <br><br>\n",
        "**2. Pretokenization** <br> a. Split to words  <br><br>\n",
        "**3. Tokenizer model** <br> a. Further spilt the words formed in the Pretokenization steps (if required) <br> b. Convert them to input_ids (integers) <br><br>\n",
        "**4. Postprocessing** <br> a. Add the special tokens to start and end of each sentence. For example BERT uses (CLS, SEP) and XLM-R uses (<s>, <\\s>) .\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSXGfiLxw5p7"
      },
      "source": [
        "The XLM-R used \"SentencePiece\" tokenizer which is based on type of subword segmentation called \"Unigram\" and encodes each input text as a sequence of Unicode characters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtA_3wf6c_dO"
      },
      "source": [
        "# **Building Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvbUufPE6yWg",
        "outputId": "fdc32fc7-5f31-4d1e-c145-ee2adb4009e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output from tokenizer: {'input_ids': [0, 21763, 37456, 15555, 5161, 7, 2356, 5753, 38, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "\n",
            "The tokens: ['<s>', '▁Jack', '▁Spar', 'row', '▁love', 's', '▁New', '▁York', '!', '</s>']\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "xlmr_model_name = 'xlm-roberta-base'\n",
        "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)\n",
        "\n",
        "# Test on a text\n",
        "text = \"Jack Sparrow loves New York!\"\n",
        "input_ids = xlmr_tokenizer(text)\n",
        "print(f\"Output from tokenizer: {input_ids}\")\n",
        "\n",
        "# For testing, return back to tokens\n",
        "xlmr_tokens = input_ids.tokens()\n",
        "print(f\"\\nThe tokens: {xlmr_tokens}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sasoUIvaJ9L"
      },
      "source": [
        "# **Tokenize the whole dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJphdzTuT3E1"
      },
      "source": [
        "Now let us write a function to tokenize the whole dataset, and further converting them to ids (in serial number)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZ3ZOTaQTymI"
      },
      "outputs": [],
      "source": [
        "# Define a function to obtain tokenization for feeding into NER classification model\n",
        "def tokenize_and_align_labels(examples):\n",
        "  # Convert this to input_ids and attention_mask\n",
        "  tokenized_inputs_ids = xlmr_tokenizer(examples[\"tokens\"], truncation = True, is_split_into_words = True)\n",
        "\n",
        "  labels = []\n",
        "\n",
        "  for idx, label in enumerate(examples[\"ner_tags\"]):\n",
        "    #\n",
        "    word_ids = tokenized_inputs_ids.word_ids(batch_index = idx)\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "      if word_idx is None or word_idx == previous_word_idx:\n",
        "          label_ids.append(-100)\n",
        "      else:\n",
        "        label_ids.append(label[word_idx])\n",
        "\n",
        "      previous_word_idx = word_idx\n",
        "\n",
        "    labels.append(label_ids)\n",
        "  tokenized_inputs_ids[\"labels\"] = labels\n",
        "  return tokenized_inputs_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipRHze55njz_"
      },
      "source": [
        "Let us apply the above function to our first German text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkBdN7PDara6"
      },
      "source": [
        "With the above function we can encode each split, so let us write a function that we can itrate over."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_KZDWC1aatK"
      },
      "outputs": [],
      "source": [
        "def encode_panx_dataset(corpus):\n",
        "  return corpus.map(tokenize_and_align_labels, batched = True, remove_columns = ['langs', 'ner_tags', 'tokens'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e055d149fac04a5dbdb5bfb8b97db135",
            "8df72c8ebc4a4895ae814dcb0b0c4706",
            "7a79231d9b5d412aadf321b3af830b50",
            "3d7d92230ff14c8996d600153c6e6b48",
            "bcef079855c04908983d62f32e8e6b9b",
            "bc8f8e04736848d685e0534d7ce04140",
            "36250be4332149669ff166032b77abc1",
            "634f8313ceca479a94dfb55ac1d0381c",
            "ee39d7e2c51c4e85945b3eb62eb3c0c2",
            "d45dc861c9d44336a11de8ad13cd5695",
            "f1381771ee934ba5be37253b410d8007"
          ]
        },
        "id": "QCoBNP0Ha4av",
        "outputId": "b8865466-e1a0-459d-e135-5271843faf80"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e055d149fac04a5dbdb5bfb8b97db135",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4580 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# By applying this function to DatasetDict object (train, test, validation), we'll obtain an encoded Dataset object per split.\n",
        "panx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])\n",
        "panx_fr_encoded = encode_panx_dataset(panx_ch[\"fr\"])\n",
        "panx_it_encoded = encode_panx_dataset(panx_ch[\"it\"])\n",
        "panx_en_encoded = encode_panx_dataset(panx_ch[\"en\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aoq2Uh_HVv_P"
      },
      "outputs": [],
      "source": [
        "index2tag = {idx: tag for idx, tag in enumerate(tags.names)} # tags.names = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n",
        "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK2stlu8ZjNc",
        "outputId": "d04adda9-8f3f-41c4-bc8b-aa3737609b1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tags.num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15JSB3Eedijh"
      },
      "source": [
        "# **Building Configuration <br>**\n",
        "The AutoConfig class contains the blueprint of the LLM model's architecture. To configure, we'll load with AutoConfig class. Further we need to modify this with number of labels (number of classes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7Wx3NtkeoKs"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoConfig\n",
        "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name, num_labels = tags.num_classes, id2label = index2tag, label2id = tag2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nALX2shsdgcM"
      },
      "outputs": [],
      "source": [
        "#from transformers import XLMRobertaConfig\n",
        "#xlmr_config = XLMRRobertaConfig()\n",
        "#print(xlmr_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jULdeW5LmtGu"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ikm9JRlzyTU-"
      },
      "source": [
        "# **Fine-Tune XLM-Roberta**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy1pD_0C0Okf"
      },
      "source": [
        "To fine-tune our model, first I'll fine-tune our base model on the German subset of PAN-X and then evaluate its zero-shot cross-lingual on French, Italian and English. For this, I'll use the Trainer() class to handle our training loop. However, to build a trainer class I need to instatinate a TrainingArguments class with all the\n",
        "required arguments.<br><br>The trainer class for our task here requires following:<br>\n",
        "\n",
        "* Initialization parameters\n",
        "* Training arguments\n",
        "* Data collator\n",
        "* Evaluation metrics\n",
        " Let us build those below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqdRvigNjAal"
      },
      "source": [
        "### **Initializing the model's paramters (loading XLM-R model's weight)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t34s-IcljhRv"
      },
      "source": [
        "Here, we may required to train several models, so to avoid intilizing a new model each time, we'll write a function to carry out the job."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvIWrDwmICmL"
      },
      "source": [
        "Here, we'll import XLMRobertaForTokenClassification pre-trained model to obtain all the model weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCcSFWgDjNYw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CBngimUIBuV",
        "outputId": "bb143995-c705-4e80-a73c-66051079f367"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import XLMRobertaForTokenClassification\n",
        "xlmr_model = (XLMRobertaForTokenClassification.from_pretrained(xlmr_model_name, config = xlmr_config).to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIgeCpywJVhB"
      },
      "source": [
        "As a quick check that we have initialized the tokenizer and model correctly, let us test our prediction on our small text \"Jack Sparrow loves New York!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2mvExNYJ48i"
      },
      "outputs": [],
      "source": [
        "input_ids = xlmr_tokenizer.encode(text, return_tensors = \"pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp6bDyY0MQjD",
        "outputId": "194acb03-c70c-4b26-ce18-5d8eefa0caeb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[    0, 21763, 37456, 15555,  5161,     7,  2356,  5753,    38,     2]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_kxJ_v0LNlI"
      },
      "source": [
        "Let us make a dataframe with the tokens and input_ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "YWCH82ZXLKzc",
        "outputId": "9985df9e-b305-4d56-ad2d-7e7e4009be46"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"!\",\n          \"\\u2581Jack\",\n          \"s\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_ids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12506,\n        \"min\": 0,\n        \"max\": 37456,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          38,\n          21763,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-2d95c08a-c3c3-4b3b-be44-24888d107b3e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>input_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>▁Jack</td>\n",
              "      <td>21763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>▁Spar</td>\n",
              "      <td>37456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>row</td>\n",
              "      <td>15555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>▁love</td>\n",
              "      <td>5161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>s</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>▁New</td>\n",
              "      <td>2356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>▁York</td>\n",
              "      <td>5753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>!</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d95c08a-c3c3-4b3b-be44-24888d107b3e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2d95c08a-c3c3-4b3b-be44-24888d107b3e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2d95c08a-c3c3-4b3b-be44-24888d107b3e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-49219a05-03f5-40f4-af4d-315ec396860a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-49219a05-03f5-40f4-af4d-315ec396860a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-49219a05-03f5-40f4-af4d-315ec396860a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  tokens  input_ids\n",
              "0    <s>          0\n",
              "1  ▁Jack      21763\n",
              "2  ▁Spar      37456\n",
              "3    row      15555\n",
              "4  ▁love       5161\n",
              "5      s          7\n",
              "6   ▁New       2356\n",
              "7  ▁York       5753\n",
              "8      !         38\n",
              "9   </s>          2"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame({'tokens': xlmr_tokens, 'input_ids':input_ids[0].numpy()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-KjY8BHRLTA"
      },
      "outputs": [],
      "source": [
        "out = xlmr_model(input_ids.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sliQABNSSNRe",
        "outputId": "a8eeb23c-ce80-4919-e934-d91acf855e1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TokenClassifierOutput(loss=None, logits=tensor([[[ 0.2990,  0.3989,  0.2003,  0.2774, -0.3361, -0.4741, -0.1420],\n",
              "         [ 0.1379,  0.4206, -0.1042,  0.1976, -0.0820, -0.3970,  0.2425],\n",
              "         [ 0.2078,  0.3332, -0.0396,  0.1272, -0.0324, -0.4847,  0.1022],\n",
              "         [ 0.2092,  0.4073, -0.1365,  0.1153, -0.0721, -0.3723,  0.1622],\n",
              "         [ 0.0357,  0.2961, -0.0518,  0.1138, -0.0320, -0.2463,  0.3257],\n",
              "         [ 0.1294,  0.2635, -0.0709,  0.2046, -0.0540, -0.3644,  0.1900],\n",
              "         [ 0.1058,  0.4104, -0.0794,  0.1863, -0.1216, -0.2923,  0.2489],\n",
              "         [ 0.1056,  0.3725, -0.0955,  0.1950, -0.0977, -0.2417,  0.3232],\n",
              "         [ 0.2676,  0.2572, -0.0899,  0.1797, -0.0669, -0.4067,  0.1845],\n",
              "         [ 0.3421,  0.4091,  0.1697,  0.2394, -0.3528, -0.4398, -0.1635]]],\n",
              "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCO8OeAtMvAg"
      },
      "source": [
        "Here, we can see that the start <s> and end </s> are given the IDs 0 and 2 respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFeSd47aNenp"
      },
      "source": [
        "Let us now pass the inputs to the model and extract the predictions by taking the argmax to get the most likely class per token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foJBbiHdQueG"
      },
      "outputs": [],
      "source": [
        "outputs = out.logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4Ijy_WEQ_O4",
        "outputId": "a181e2df-b9ad-4d05-9da2-ad98922a2992"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.2990,  0.3989,  0.2003,  0.2774, -0.3361, -0.4741, -0.1420],\n",
              "         [ 0.1379,  0.4206, -0.1042,  0.1976, -0.0820, -0.3970,  0.2425],\n",
              "         [ 0.2078,  0.3332, -0.0396,  0.1272, -0.0324, -0.4847,  0.1022],\n",
              "         [ 0.2092,  0.4073, -0.1365,  0.1153, -0.0721, -0.3723,  0.1622],\n",
              "         [ 0.0357,  0.2961, -0.0518,  0.1138, -0.0320, -0.2463,  0.3257],\n",
              "         [ 0.1294,  0.2635, -0.0709,  0.2046, -0.0540, -0.3644,  0.1900],\n",
              "         [ 0.1058,  0.4104, -0.0794,  0.1863, -0.1216, -0.2923,  0.2489],\n",
              "         [ 0.1056,  0.3725, -0.0955,  0.1950, -0.0977, -0.2417,  0.3232],\n",
              "         [ 0.2676,  0.2572, -0.0899,  0.1797, -0.0669, -0.4067,  0.1845],\n",
              "         [ 0.3421,  0.4091,  0.1697,  0.2394, -0.3528, -0.4398, -0.1635]]],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbxJXhM-S6rw"
      },
      "outputs": [],
      "source": [
        "preds = torch.argmax(outputs, dim = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqLmD7C7S7e0",
        "outputId": "fe4d18da-eb1d-4c23-d3a8-cde5b71b7f01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 6, 1, 1, 1, 0, 1]])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhUTumc6SZwA",
        "outputId": "db23f954-a387-464d-b133-78295e425e96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 6, 1, 1, 1, 0, 1]])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = torch.argmax(outputs, dim = 2)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A99HAVDdS9X2",
        "outputId": "7e0c30bf-b8a2-411c-ebcf-6839ae0b7e1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 7])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhRgjgXTXPZ-",
        "outputId": "06d09e2e-fbcd-4a51-8a33-a18babf2bcf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of token in the sequence: 10\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of token in the sequence: {len(xlmr_tokens)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CUrOeAAWB9-",
        "outputId": "67cc5e31-6b49-4dad-9b75-c6a2fc942dca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of predictions:10\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of predictions:{len(predictions[0])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2FYsHgXY2N_"
      },
      "outputs": [],
      "source": [
        "final_preds = [tags.names[p] for p in predictions[0].numpy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m29n0o9QaZzO",
        "outputId": "535babaf-0dbf-4824-eb26-2412a21abeff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['B-PER',\n",
              " 'B-PER',\n",
              " 'B-PER',\n",
              " 'B-PER',\n",
              " 'I-LOC',\n",
              " 'B-PER',\n",
              " 'B-PER',\n",
              " 'B-PER',\n",
              " 'O',\n",
              " 'B-PER']"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hph_nryLa7eh"
      },
      "source": [
        "Very Bad! Our token classification layer with random weights leaves it to perform bad. However, to test in other language text, let us wrap it in a function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do8VyB7-bnIA"
      },
      "outputs": [],
      "source": [
        "def tag_text(text, tags, model, tokenizer):\n",
        "  tokens = tokenizer(text).tokens\n",
        "  input_ids = xlmr_tokenizer(text, return_tensors = 'pt')\n",
        "\n",
        "  # Get prediction over 7 possible classes\n",
        "  outputs = model(input_ids)[0]\n",
        "\n",
        "  #Take argmax to obtain most likely class per token\n",
        "  predictions = torch.argmax(outputs, dim = 2)\n",
        "\n",
        "  # Convert to DataFrame\n",
        "  preds = [tags.names[p] for p in predictions[0].numpy()]\n",
        "  return pd.DataFrame([tokens, preds], index = [\"tokens\", \"Tags\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aoia7y6ujNlJ"
      },
      "outputs": [],
      "source": [
        "from transformers import XLMRobertaForTokenClassification\n",
        "def model_init():\n",
        "  return (XLMRobertaForTokenClassification.from_pretrained(xlmr_model_name, config = xlmr_config)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBnzcwSp1BcU"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "num_epochs = 3\n",
        "batch_size = 24\n",
        "logging_steps = len(panx_de_encoded[\"train\"])//batch_size\n",
        "model_name = f\"{xlmr_model_name}-finetuned-panx-de\" # It'll be our ouput directory\n",
        "training_args = TrainingArguments(output_dir = model_name,\n",
        "                                  log_level = \"error\",\n",
        "                                  num_train_epochs = num_epochs,\n",
        "                                  per_device_train_batch_size = batch_size,\n",
        "                                  per_device_eval_batch_size = batch_size,\n",
        "                                  eval_strategy = \"epoch\",\n",
        "                                  save_steps = 1e6, # We kept this steps to high number to spped up the training process\n",
        "                                  weight_decay = 0.01,\n",
        "                                  disable_tqdm = False,\n",
        "                                  logging_steps = logging_steps,\n",
        "                                  push_to_hub = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uapEw72-nO2n"
      },
      "source": [
        "## **Data Collator** <br>\n",
        "With the \"data collator\" we can pad each input sequence to the largest sequence length in a batch. For this we'll use Hugging face's DataColllatorForTokenClassification method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbH7mkDWoqw9"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer = xlmr_tokenizer, padding = True, label_pad_token_id = -100, return_tensors = 'pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puZulTCrhGen"
      },
      "source": [
        "## **Evaluation metrics**\n",
        "\n",
        "The token classification performance being a classification problem will be evailuated by calculating Recall, Precison and f1-score. To carry out this job, we'll use **seqeval** library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwrFVgDQhURX",
        "outputId": "1457f6dd-f8a5-43a5-9e0c-9bb5d92a8302"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from seqeval) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=556ad3bbf448c1f885b9d0c2911187c0b9c0533706865a898622447df82dd657\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HG63urdhPmF"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaGOvKCu4Ilz"
      },
      "source": [
        "As seqeval accepts list of lists, we'll write a function to obtain the predictions and label ids lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJfZS23E__Uo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def align_predictions(predictions, label_ids): # y_pred = predictions , y_true = label_ids\n",
        "  preds = np.argmax(predictions, axis = 2)\n",
        "  batch_size, seq_len = preds.shape\n",
        "\n",
        "  labels_list, preds_list = [], []\n",
        "\n",
        "  for batch_idx in range(batch_size):\n",
        "    example_labels, example_preds = [], []\n",
        "    for seq_idx in range(seq_len):\n",
        "      # Ignore the label IDs = -100\n",
        "      if label_ids[batch_idx,seq_idx] != -100:\n",
        "        example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
        "        example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
        "\n",
        "    labels_list.append(example_labels)\n",
        "    preds_list.append(example_preds)\n",
        "\n",
        "  return preds_list, labels_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faSPydnTLfMo"
      },
      "outputs": [],
      "source": [
        "# Define a function to compute metrics\n",
        "def compute_metrics(eval_pred):\n",
        "  y_pred, y_true = align_predictions(eval_pred.predictions, eval_pred.label_ids)\n",
        "  return {\"f1\": f1_score(y_true, y_pred)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JsciuXSqaRo"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(model_init = model_init,\n",
        "                  args = training_args,\n",
        "                  data_collator = data_collator,\n",
        "                  compute_metrics = compute_metrics,\n",
        "                  train_dataset = panx_de_encoded[\"train\"],\n",
        "                  eval_dataset = panx_de_encoded[\"validation\"],\n",
        "                  processing_class = xlmr_tokenizer\n",
        "                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "MrM_nbwzxfTV",
        "outputId": "f9dba0aa-b1b7-4085-fd59-65d495e906cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdamayanti-naik222\u001b[0m (\u001b[33mdamayanti-naik222-none\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250902_142148-27x4yian</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/damayanti-naik222-none/huggingface/runs/27x4yian' target=\"_blank\">treasured-pyramid-31</a></strong> to <a href='https://wandb.ai/damayanti-naik222-none/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/damayanti-naik222-none/huggingface' target=\"_blank\">https://wandb.ai/damayanti-naik222-none/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/damayanti-naik222-none/huggingface/runs/27x4yian' target=\"_blank\">https://wandb.ai/damayanti-naik222-none/huggingface/runs/27x4yian</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1575' max='1575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1575/1575 5:44:36, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.271400</td>\n",
              "      <td>0.156047</td>\n",
              "      <td>0.822873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.128000</td>\n",
              "      <td>0.133228</td>\n",
              "      <td>0.855646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.130850</td>\n",
              "      <td>0.863116</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1575, training_loss=0.16080530109859648, metrics={'train_runtime': 20916.1314, 'train_samples_per_second': 1.804, 'train_steps_per_second': 0.075, 'total_flos': 854205461835792.0, 'train_loss': 0.16080530109859648, 'epoch': 3.0})"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtRfiOtWNha7"
      },
      "source": [
        "## Fine-tune with Trainer API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTI_lVKHM2Dy"
      },
      "source": [
        "Now, we'll create a trainer for our model to see its performance providing all required parameters that we've created already."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "O80_r3AG8tfM",
        "outputId": "bd70a5cf-27ed-46a7-8193-8b9b2d0c90f8"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'trainer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1663994881.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'loss'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'eval_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eval_f1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Training Loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eval_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Validation Loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eval_f1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"F1\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Training Loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(trainer.state.log_history)[['epoch','loss' ,'eval_loss', 'eval_f1']]\n",
        "df = df.rename(columns={\"epoch\":\"Epoch\",\"loss\": \"Training Loss\", \"eval_loss\": \"Validation Loss\", \"eval_f1\":\"F1\"})\n",
        "df['Epoch'] = df[\"Epoch\"].apply(lambda x: round(x))\n",
        "df['Training Loss'] = df[\"Training Loss\"].ffill()\n",
        "df[['Validation Loss', 'F1']] = df[['Validation Loss', 'F1']].bfill().ffill()\n",
        "df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXTh9BqQ-Ia8"
      },
      "source": [
        "# **Cross-Lingual Transfer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84QjdRah-T2E"
      },
      "outputs": [],
      "source": [
        "# A function to evaluate the metrics\n",
        "def get_f1_score(trainer, dataset):\n",
        "    return trainer.predict(dataset).metrics[\"test_f1\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F76sPTnR-syC"
      },
      "source": [
        "Evaluate on German test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkebRBC4-UDu"
      },
      "outputs": [],
      "source": [
        "f1_scores = defaultdict(dict)\n",
        "f1_scores[\"de\"][\"de\"] = get_f1_score(trainer, panx_de_encoded[\"test\"])\n",
        "print(f\"F1-score of [de] model on [de] dataset: {f1_scores['de']['de']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl_1PbY1_Ppv"
      },
      "source": [
        "Let us see the fine-tuned model's performance on French, Italian and English."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2jEA0Le3MNH"
      },
      "outputs": [],
      "source": [
        "# A function to evaluate on all test data\n",
        "\n",
        "def evaluate_lang_performance(lang, trainer):\n",
        "    panx_ds = encode_panx_dataset(panx_ch[lang])\n",
        "    return get_f1_score(trainer, panx_ds[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tgaoTNi_r_U"
      },
      "outputs": [],
      "source": [
        "f1_scores[\"de\"][\"fr\"] = evaluate_lang_performance(\"fr\", trainer)\n",
        "print(f\"F1-score of [de] model on [fr] dataset: {f1_scores['de']['fr']:.3f}\")\n",
        "\n",
        "\n",
        "f1_scores[\"de\"][\"it\"] = evaluate_lang_performance(\"it\", trainer)\n",
        "print(f\"F1-score of [de] model on [it] dataset: {f1_scores['de']['it']:.3f}\")\n",
        "\n",
        "f1_scores[\"de\"][\"en\"] = evaluate_lang_performance(\"en\", trainer)\n",
        "print(f\"F1-score of [de] model on [en] dataset: {f1_scores['de']['en']:.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8gO5KmU5C-m"
      },
      "source": [
        "So far, we fine-tuned our XLM-R model on German dataset, and observed a f1-socore of 85%, while in other language dataset, it yields modest performance which is really a concern and we need to work on it to improve the performance significantly. <br>\n",
        "\n",
        "In order to work towards it, let us first train our XLM-R model on a multilingual dataset with concatenated corpus of German, Freanch, Italian and English.\n",
        "\n",
        "For simplicity, I'll keep the same hyperparameters from the fine-tuning run on the German corpus, except the logging_steps argument of Training Arguments to account for the increase size of the training multilingual corpus.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWSw_njbApBC"
      },
      "outputs": [],
      "source": [
        "# def train_on_subset(dataset, num_samples):\n",
        "#     train_ds = dataset[\"train\"].shuffle(seed=42).select(range(num_samples))\n",
        "#     valid_ds = dataset[\"validation\"]\n",
        "#     test_ds = dataset[\"test\"]\n",
        "#     training_args.logging_steps = len(train_ds) // batch_size\n",
        "\n",
        "#     trainer = Trainer(model_init=model_init, args=training_args,\n",
        "#         data_collator=data_collator, compute_metrics=compute_metrics,\n",
        "#         train_dataset=train_ds, eval_dataset=valid_ds, tokenizer=xlmr_tokenizer)\n",
        "\n",
        "#     trainer.train()\n",
        "\n",
        "\n",
        "#     f1_score = get_f1_score(trainer, test_ds)\n",
        "#     return pd.DataFrame.from_dict(\n",
        "#         {\"num_samples\": [len(train_ds)], \"f1_score\": [f1_score]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-r4y_ccAIio"
      },
      "source": [
        "To fine tune more let us use sample of different size and take the best  output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAa70s9JAY-6"
      },
      "outputs": [],
      "source": [
        "# for num_samples in [500, 1000, 2000, 4000]:\n",
        "#     metrics_df = metrics_df.append(\n",
        "#         train_on_subset(panx_de_encoded, num_samples), ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH4URPQ3A_N1"
      },
      "source": [
        "# **Fine-Tuning on Multiple Languages corpus**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1OukHIYjiWG"
      },
      "source": [
        "To carry out this opration, first I'll concatetanate all four languages corpus of  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvKYv3U6BWpL"
      },
      "outputs": [],
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "def concatenate_splits(corpora):\n",
        "    multi_corpus = DatasetDict()\n",
        "    for split in corpora[0].keys():\n",
        "        multi_corpus[split] = concatenate_datasets(\n",
        "            [corpus[split] for corpus in corpora]).shuffle(seed=42)\n",
        "    return multi_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvUM0eB_Bd_E"
      },
      "outputs": [],
      "source": [
        "panx_de_fr_it_en_encoded = concatenate_splits([panx_de_encoded, panx_fr_encoded, panx_it_encoded, panx_en_encoded])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DucQc88UBwqQ"
      },
      "outputs": [],
      "source": [
        "training_args.logging_steps = len(panx_de_fr__it_en_encoded[\"train\"]) // batch_size\n",
        "\n",
        "training_args.output_dir = \"xlm-roberta-base-finetuned-panx-de-fr\"\n",
        "\n",
        "trainer = Trainer(model_init = model_init,\n",
        "                  args = training_args,\n",
        "                  data_collator = data_collator,\n",
        "                  compute_metrics = compute_metrics,\n",
        "                  tokenizer = xlmr_tokenizer,\n",
        "                  train_dataset = panx_de_fr_it_en_encoded[\"train\"],\n",
        "                  eval_dataset = panx_de_fr_it_en_encoded[\"validation\"])\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEsxV0dpCDhf"
      },
      "outputs": [],
      "source": [
        "for lang in langs:\n",
        "    f1 = evaluate_lang_performance(lang, trainer)\n",
        "    print(f\"F1-score of [de-fr-it-en] model on [{lang}] dataset: {f1:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIM2e9-9CDu0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5BiqliXNHcU"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5KSI2dGnKBa"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbdiSgyLgqXT"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIUT3RjVZHce"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2P1FWwjZHG0"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2C2nz9iOoJZ"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}